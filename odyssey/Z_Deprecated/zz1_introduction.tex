\section{Introduction}
\label{sec:introduction}

This work focuses \emph{solely} on 
%distributed systems that solve consensus. More specifically, 
replicated datastores that implement reads and atomic Read-Modify-Writes (\RMW).
%~\footnote{ 
Crucially, systems that offer \RMWs~must solve consensus.
%}.
Such systems are the backbone of modern online services and as such are ubiquitous in today's world. Apart from underlining the importance of such systems, this statement  highlights one more fact: 
%thousands of software designers all around the world must reason about such systems on a daily basis.% as they have to interface-with or build such systems . 
%Indeed, 
the -- once -- niche area of distributed consensus, is today an essential part of the day-to-day operations for thousands of developers.  However, despite its increasing popularity, the nature of the consensus problem remains unforgivingly subtle.

Assisting the developer in navigating and comprehending the problem, is a thirty-years old, rich literature around the problem of consensus. 
Alas, whilst rich, the consensus literature is also vast, with papers often written in a complicated language -- for legacy reasons-- and even more commonly, lacking concrete system evaluations.
Making matters worse, during the last thirty years, the hardware landscape has changed dramatically, challenging the prevalent assumption about which metrics a protocol must optimize. 
Crucially, multi-core servers and high bandwidth networks are creating a shift towards protocols that prioritize request-level parallelism over per-request message count.



\custvspace
In this work, we address these issues by providing a taxonomy of consensus protocols along with an evaluation of six prominent protocols as complete systems optimized for modern hardware.

Specifically, we categorize existing consensus protocols into a taxonomy that consists of four classes. % of existing consensus protocols.% into four classes. 
In order to understand the performance relation of each class, we evaluate representative protocols from all four classes. % (we evaluate three protocols from the "conflict-elimination" class to capture its variations). 
Crucially, all protocols are %implemented for modern hardware. They are 
designed to be  heavily multi-threaded and utilise all known strategies to leverage RDMA-capable networks.
In addition, the comparison is fair from the grounds-up: \ie all systems are developed in the same ecosystem with the same set of assumptions and share as much code as possible (\eg shared Key-Value-Store, RDMA usage patterns, concurrency control, thread-pinning strategy, client interface etc.). The code will be open-sourced.

Our taxonomy will provide the system designer with a meticulous examination of the trade-offs amongst consensus protocols, allowing them to navigate the vast literature.
In addition, it will provide an apples-to-apples performance comparison of protocols under the assumptions that matter -- \ie modern datacenter hardware. The comparison reveals a number of surprising results that challenge conventional wisdom.

Finally, amongst the well-known systems that are evaluated in this work, we also implement and measure \emph{All-aboard Paxos}, which is sketched in Howard's thesis~\cite{Howard:2019} as a Flexible Paxos~\cite{Howard:2018} application. To our knowledge this work is the first to draw a complete specification of the protocol, build it into a system and evaluate its performance.
% Finally, it will reveal surprising results, that challenge the conventional wisdom. 

\begin{comment}
Finally, as part of our evaluation, we implement and measure for the first time \emph{All-aboard Paxos}, which is sketched in Howard's thesis~\cite{Howard:2019} as a Flexible Paxos~\cite{Howard:2018} application. We draw a complete specification, measure its limits and present it as a viable option.



\beginbsec{What this paper does}
The purpose of this paper is dual: 1) it is addressed to the %needs of the 
%modern 
system designer, aiming to provide them with a map to navigate the vast literature of consensus. 2) It addresses the research community, aiming to 
%challenge conventional wisdom, on what are the modern metrics for 
drive the dialogue on 
high-performance consensus algorithms, in the light of contemporary hardware.
%, bringing to light a class of protocols, that has not yet received the warranted attention .% into new directions
%attempts to  However, through this work we also aspire to drive the research community into to pursue new directions
Towards these goals we present: a taxonomy of consensus protocols and a comprehensive evaluation of high-performance implementations of at least one representative protocol from each class.  
Our taxonomy meticulously examines the trade-offs of the different techniques in the light of modern era hardware, revealing surprising results, that challenge the conventional wisdom, while also bringing to light a class of protocols, that has not yet received the warranted attention.
In every step of the way, we substantiate our claims through the evaluated systems.
\end{comment}

\subsection{The Taxonomy}

%\custvspace
%\noindent
%Our taxonomy classifies protocols based on how they deal with the performance challenge, which we explain below.

%\beginbsec{Performance challenge in consensus protocols}
Consensus protocols must account for failures. %, and that presents a challenge on providing performance.
However, a failure cannot be differentiated from a slow node, thus presenting the  sender of a message with a dilemma, when a response has not been received. On the one hand, if the receiver has failed and the sender chooses to wait for the response, it will wait indefinitely. On the other hand, if the receiver is merely slow, and the sender chooses to not wait for the response, then the correctness of the protocol may be violated. 

The typical solution to this issue, is to restrict the failures that can be tolerated to a fixed number, $f$. Then, on broadcasting a message to $N$ servers, the sender can safely wait for $N-f$ responses. This way the sender only waits indefinitely, if more than $f$ servers have failed.%, a behaviour allowed by the specification.

Note the implications of this solution: protocol specifications can not enforce the invariant that a broadcast message reaches all replicas. As a result, when two different servers attempt to execute \emph{conflicting commands} (\ie commands that modify the same piece of data), and broadcast that intention, it is acceptable that they do not learn of each other's command. This handicap burdens the protocol with additional complexity to resolve such conflicts.

Therefore, there is great complexity in designing a protocol that solve consensus under these two assumptions: 1) broadcasts are not guaranteed to reach all recipients and 2) nodes can attempt concurrent commands. Specifically, we can quantify said complexity, because there is only one protocol that solves consensus under both assumptions, that is Classic Paxos (CP)~\cite{Lamport:1998}. Dealing with the two assumptions forces CP to follow a very complicated path in its common operation that diminishes performance.

Every other consensus protocol we know of relaxes one of the two assumptions in its common operation to reduce the common case complexity and thus increase performance.

\begin{comment}
However, this solution has a direct implication on performance: protocol specifications can not enforce the invariant that a broadcast message reaches all replicas. This handicap presents a challenge in designing high-performance protocols, seeing as \emph{in the face of conflicting consensus commands, %proposed by different servers
the ability to reach all replicas is crucial.}
\end{comment}

\beginbsec{Fast-/slow-path}
Specifically, consensus protocols attempt to either remove the possibility of conflicts, or grant the ability to reach all replicas. They do so through their \emph{fast-path}. Precisely,
protocols leverage the observation that failures are not the common case, which allows the protocol to specify a \emph{fast-path}: an operational mode for the common-case, fault-free operation. 
When a fault occurs~\footnote{ For simplicity, we refer to a suspected failure, simply as failure},
%(or is suspected to have occurred)
then the protocol can specify a transition to a \emph{slow-path}, where the protocol handles the suspected failure and returns to the fast-path.

% \beginbsec{The Classification}
\custvspace
\noindent Our taxonomy classifies protocols based on this fast-path/slow-path approach. 

\input{4_incl_graphics/taxonomy-table}

\beginbseceval{Class-1: Conflict-elimination} 
The fast-path of this class eliminates the possibility of conflicting commands, typically by designating a server as the leader. The leader then locally resolves conflicts and notifies the rest of the replicas (\ie the \emph{followers}). When the leader eventually fails, then the slow-path kicks in: the rest of the servers elect a new leader and revert to the fast-path. 

\beginbseceval{Class-2: Stable-configuration}
In this class, the fast-path assumes that the server configuration is always known, and thus all replicas are reachable at any given time. This allows the fast-path to ensure that \emph{all} replicas are notified of any new write, which substantially simplifies resolving conflicts.

\beginbseceval{Class-3: Speculation} 
This class implements the fast-/slow-path approach at the request-granularity. Specifically, it allows an early commit after a single round of broadcast, if there were no conflicts and/or a sufficient number of replicas has been gathered.
If either condition is not met, the request goes in to the slow-path, executing an additional broadcast round. It is thus, a per-request, speculative technique, with a fallback. 

\begin{comment}
The potential upside of this approach is is not only performance but also high availability. The timeouts are implemented  per-request and, more crucially, the penalty of timing-out is only a few broadcast rounds for the offending request. Therefore the timeouts can be arbitrarily small, allowing for high availability.

This class has not received substantial attention from the research community. 
We remedy this by evaluating 

% the only well-known protocol with that nature is EPaxos, which is underpinned by very complicated algorithm that communicates dependencies and build graphs of dependencies. 
% An exemplar protocol in this class is 
% However, there is another, recently proposed protocol, which is simpler and more efficient: 
\emph{All-aboard Paxos}, a newly proposed, but never-before evaluated protocol. We believe that showcasing the 
%We evaluate this protocol, showcasing 
the benefits and the shortcomings of this approach, can have a profound impact in the research discussion on distributed consensus.
%but also underlining the pitfalls.
\end{comment}



\beginbseceval{Class-4. Classic Paxos} % (favouring availability)}
For completeness, we also include protocols without a fast-path. Such protocols do no try to optimize performance by make replicas reachable, or eliminate conflicts; rather they deal with these issues by being constantly in the slow-path, assuming the constant presence of failures. 
The only protocol we know of in this category is Classic-Paxos (CP). 
%CP incurs additional overhead in its common case, in order to maintain a complete availability robustness.
Challenging the conventional wisdom, we show that because of its concurrent nature, CP can offer competitive performance in today's hardware. 




\beginbsec{Contributions}
\squishlistContrib
\item We provide a taxonomy of consensus algorithms based on the fast-/slow-path approach.
\item For each class of our taxonomy we describe: the availability vs performance trade-off, how reads can be added, which workloads are favoured, what is the supported API and the subtle implication of the class. 
\item Alongside each class's description, we provide an evaluate an implementation of at least one representative protocol with the following properties: \RDMA-enabled, highly-multithreaded, implements reads (a common omission in consensus benchmarking) and runs over state-of-the art Key-Value Store.
\squishend
\vasilis{stopping here}

\begin{comment}
This new reality has motivated the research community to propose a plethora of new protocols and optimizations, attempting to  improve both performance  and comprehensibility of such systems. Meanwhile, advances in the hardware landscape, such as \RDMA-enabled, high-bandwidth networks and multi-core servers challenge the established performance metrics, making
%of old. 
protocols that leverage the new capabilities increasingly more appealing.

Making matters worse, the performance evaluations of proposed protocols are rarely satisfying. In most cases the performance is not pushed to the edge, with the most common offences being, no multi-threading, not RDMA-enabled, no implementation of reads, no underling data structure (\eg KVS) and  not open-sourced. While in some cases protocols are not implemented at all. There is thus a clear need to provide the developer with a comprehensive map of the design space, where all the protocol options and their trade-offs are laid out and properly evaluated.



In this work we answer this call. We break-down, analyze and explain existing protocols by creating a comprehensive taxonomy of techniques and their associated trade-offs while also evaluating a proper high-performance implementation for each class.


\beginbsec{What this paper does}
In order to do so, we first create a protocol taxonomy, where protocols are classified based on their availability guarantees. For each class, we enumerate the design choices and their trade-offs and we implement at least one representative protocol, in an \RDMA-based and multi-threaded manner, applying all proposed optimizations.
system   of the techniques and we create high-performance
We taxonomize the available techniques with respect to their availability guarantees. We build representative sys


\end{comment}
\begin{comment}
%The emergence of new protocols as well as advances in the hardware landscape

Alas, we deem the attempt to provide the system designer with a complete and comprehensive description of the design space unsatisfying. The designer is bombarded with a superabundance of options, metrics and promises, where %Perhaps, owning to the antagonistic nature of research, 
trade-offs are often not described in their entirety, with important pieces being left out. 
This does not necessarily constitute a criticism on the existing work. 
Often implementation choices have very subtle side effects that can be 1) out of the scope of a proposal and 2) hard or even impossible to characterize and explain within a research paper. 
Fleshing out such subtleties in the design space is what largely  necessitates this paper. 


To make this more concrete, consider the subtlety on the following example, which illustrates the impact of sharding in the API and single-client performance.

\beginbsec{Example}
Assume a linearizable KVS with a single leader which serves all writes. In addition, assume that there is a client that connects to the KVS leader and issues a number of writes to different keys and -- crucially -- cares that the writes are applied in the intended order. 
The designers, inspired by a new OSDI paper, optimize the system by electing a different leader for each key to increase the overall throughput. 
Note, the impact of this optimization on the client demands: its writes must now be steered to the different leaders: whereas before a single leader would execute all writes and could thus locally enforce their order, now the order must be enforce by issuing requests synchronously 
intended which means that the client itself must issue the requests synchronously. I.e., the client cannot issue all of its writes in a single packet, rather it must itself ensure that the order of its writes are maintained by issuing them one-by-one, waiting for each one to complete before preforming the next.


% This is largely what necessitates our work.

\beginbsec{What this paper does}
In this work, we answer the following question: \emph{What is the true cost of strong consistency?} 
We answer this question by describing the \emph{complete} trade-off for each of the existing protocols that can offer strong consistency semantics. 
The emphasis on \qt{complete} is crucial: we do not look to measure which protocol prevails for any one given metric or for any one given workload. Rather we look to characterize every aspect of the trade-offs. 

Assume a linearizable KVS with a single leader which serves all writes. The designers, inspired by a new OSDI paper, optimize the system by allowing all nodes to be leaders for different shards of the KVS, thus increasing the the overall throughput. 
Whilst the overall throughput is indeed likely to increase; a number of questions regarding the complete trade-off of the optimization may remain unanswered. What is the impact on the client side, which now may need to communicate with multiple leaders? Does single-client performance remain unaffected? On suspecting a leader, how are their keys distributed? And more importantly, on a false positive, how does the suspected node reclaim their shard? 

% It is entirely conceivable that the authors of the OSDI paper

In this work, we bring to light the complete trade-offs of implementation choices with their various subtleties and side-effects. We demonstrate the impact of the trade-offs with quantitative data where possible or with qualitative data where not.

\beginbsec{What this paper does \emph{not} do}
In this work we will \emph{not} argue for any one protocol or optimization and we will \emph{not} look to pick on any given research proposal. 



This paper, discuss the impact of this optimization
For instance, assume 
that how a decision made for a consensus protocols affects the client API, how can reads be implemented, how can faults be detected. Performance can be achieved at the cost of availability, consistency, but also even more subtle properties. 



Therefore, whilst the optimization may have increased the overall throughput of the system, the throughput of a single client may have decreased.
\end{comment}

\begin{comment}


\vasilis{Where do rotating coordinators fit in this picture?}

\vasilis{who replies to clients, in the face of help and can we hope to preserve the exactly once semantics}

\vasilis{What if the link between two nodes is down. Who can deal with that?}


to chart the design space of linearizable and consensus protocols. After bucketizing exisiting research proposals and provide the complete trade-offs


Purpose.
the designer is bombarded with a superabundance of options choices, metrics, promises.
Some promise their system will be fast based on number of rtts, or locality, conurrency and so on, while other have even promised supremacy through understanandability.
We aim to focus on what is left out. 
Perceived optimizations are more often than not trade-offs, where the sacrificed property is not revealed and is often subtle. Indeed the dimens
Performance can be claimed, when reducing the number of rtts, but at the cost of the trhroughput or load balancing  blind to throughput, or load balancing or skew,
A lot of the systems dont discuss how to do reads, they dont evaluate over actual databases where skew is a possibility
We wish to provide clarity to the state of affairs. We intend to provide




3 types of fast-slow path w.r.t transition in and out

1. fully \qt{synchronous}:
must gather all acks, local lin reads: require leases. Otherwise reads are SC.
Solutions that give leases to quorums -- are still all-acks, but between leases -- like the monty hall problem.
Yes, there are local lin reads, but what is the actual cost of leasing?
Slow path transition: through config change, e.g. a Paxos protocol
Problems: stragglers, big availability penalty.

2. with a leader:
Simply, elect new leader on suspecting the leader. Better availability but very tricky transition in and out of the slow path. A new leader signals a new epoch and the transition between epochs must be clear.
What about reads? if the leader reaches all, then it is in the previous category, if not there is no hope of local lin reads. Can you get SC reads by reading locally, only in Zookeeper.
Performance: not balancing nw and cpu resources
What about multiple leaders then? If it is lin it is composable and thus possible. Not so fast: partitions have to change ownership, making it even more tricky to transition in and out of slow paths: remember that the availability win is because the leader is not kicked out of the configuration rather it has changed, but with multiple leaders all must be leaders, so when someone is suspected, but turns out to be alive, they must be granted their keys back!! Clients loose the ability to batch and issue requests asynchronously. Skew also an obvious issue

3. No leader: 
Paxos only slow path. Definitely not a great idea -- horrible with skew! --- but what you see is what you get. Per-key leaders are trivial to implement. 

4. Fast-slow path with zero penalty transition (arbitrarily small timeouts)
All-aboard paxos: optimization with seamless transition in and out of the slow path! Per-key is a go, but skew still a huge issue!!! 


Metrics:
RTTS? Concurrency? Locality?


Consistency, barriers are super useful but what about compositionality?

API: Do you actually need consensus? What is the space? ABD is only slow path, but probably still better than all consenus solutions. Hermes is pretty good for this.

Vector clocks: Once and for all: no RMWS, no W to R, concurrency problems, indefinite buffering issues.
\end{comment}